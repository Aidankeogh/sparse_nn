{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import gauss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputNeuron():\n",
    "    def __init__(self, network, priority):\n",
    "        self.priority = priority\n",
    "        self.net = network # the network this belongs to\n",
    "        self.a = torch.tensor(0., requires_grad = False)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.priority) + \"\\t\" + str(float(self.a))\n",
    "        \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, network, priority, a_func = F.relu):\n",
    "        self.priority = priority\n",
    "        self.net = network # the network this belongs to\n",
    "        \n",
    "        self.f = a_func\n",
    "        self.a = torch.tensor(0., requires_grad = True) # The activation value of the neuron\n",
    "        self.w = torch.tensor([gauss(0,1)],requires_grad = True ) # The weights \n",
    "        self.i = torch.tensor([0.], requires_grad = False) # The input values\n",
    "        \n",
    "        self.in_keys = [] # keys to grab inputs from\n",
    "        self.num_connections = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.priority) + \"\\t\" + str(float(self.a))\n",
    "            \n",
    "    \n",
    "    def forward(self):\n",
    "        temp = [torch.tensor(1.)] # bias\n",
    "        for key in self.in_keys:\n",
    "            temp.append(self.net[key].a)\n",
    "        self.i = torch.stack(temp)\n",
    "        self.a = torch.dot(self.i,self.w)\n",
    "        self.a = self.f(self.a)\n",
    "        \n",
    "    def add_connection(self,index):\n",
    "        self.w.requires_grad = False\n",
    "        self.w = torch.cat([self.w, torch.tensor([gauss(0,1)])])\n",
    "        self.i = torch.cat([self.i, torch.tensor([0.])])\n",
    "        self.w.requires_grad = True\n",
    "        \n",
    "        self.in_keys.append(index)\n",
    "        self.num_connections += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self,n_in,n_out,max_hidden = 5000, out_a_func = identity): \n",
    "        # self.net actually links them to their node. \n",
    "        self.max = max_hidden\n",
    "        self.net = {}\n",
    "        #Priority 0-1 = input, 1-9 = hidden, 9-10 = output\n",
    "        self.priorities = []\n",
    "        self.cur = 0\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.outputs = torch.empty(n_out, requires_grad=True)\n",
    "        \n",
    "        for i in range(n_in):\n",
    "            p = i/n_in\n",
    "            self.priorities.append(p)\n",
    "            self.net[p] = InputNeuron(self, p)\n",
    "            \n",
    "        for i in range(n_out):\n",
    "            p = 9+i/n_out\n",
    "            self.priorities.append(p)\n",
    "            self.net[p] = Neuron(self, p, a_func = out_a_func)\n",
    "            \n",
    "    def __getitem__(self,key):\n",
    "        return self.net[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for p in self.priorities:\n",
    "            yield self.net[p]\n",
    "            \n",
    "    def __call__(self,inputs):\n",
    "        self.enter(inputs)\n",
    "        self.forward()\n",
    "        return self.outputs\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for p in self.priorities[self.n_in:]:\n",
    "            params.append(self[p].w)\n",
    "        return params\n",
    "\n",
    "    def enter(self,inputs):\n",
    "        inputs = inputs.view(-1)\n",
    "        for neuron, t in zip(self,inputs):\n",
    "            neuron.a = t\n",
    "            \n",
    "    def forward(self):\n",
    "        for p in self.priorities:\n",
    "            self[p].forward()\n",
    "        \n",
    "        temp = []\n",
    "        for p in self.priorities[-self.n_out:]:\n",
    "            temp.append(self[p].a)\n",
    "        self.outputs = torch.stack(temp)\n",
    "        [n.a.retain_grad() for n in net]\n",
    "        \n",
    "    def add_neuron(self,in_connections,out_connections):\n",
    "        \n",
    "        min_priority = max(in_connections + [1])\n",
    "        for p in self.priorities:\n",
    "            if p > min_priority:\n",
    "                max_priority = p\n",
    "                break\n",
    "        new_priority = (min_priority + max_priority)/2\n",
    "        self.priorities.append(new_priority)\n",
    "        self.priorities.sort()\n",
    "        self.net[new_priority] = Neuron(self,new_priority)\n",
    "        for i in in_connections:\n",
    "            self.net[new_priority].add_connection(i)\n",
    "        for o in out_connections:\n",
    "            self.net[o].add_connection(new_priority)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net = Network(800,4)\n",
    "inputs = torch.randn(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net.add_neuron([0,0.75,0.875],[9])\n",
    "net.add_neuron([0.125,0.75,0.875],[9.25])\n",
    "net.add_neuron([0,0.25,0.5],[9.5])\n",
    "net.add_neuron([0,0.75,0.375],[9.75])\n",
    "#net[9].add_connection(0.875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "target = torch.tensor([10.0,5.0,3.0,20.0])\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    inputs = torch.randn(800)\n",
    "    out = net(inputs)\n",
    "    loss = loss_fn(out,target)\n",
    "    loss.backward()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(out)\n",
    "        print(net[9].w)\n",
    "    #tqdm.write(str(net[9].a.grad))\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9,  1,  9,  1,  7,  8,  0,  5,  2,  6,  9,  3,  1,  1,\n",
      "         4,  4,  7,  0,  5,  9,  3,  7,  4,  6,  2,  2,  7,  7,\n",
      "         3,  1,  3,  7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(28*28,10)\n",
    "\n",
    "#Add random connections\n",
    "for out in net.priorities[-net.n_out:]:\n",
    "    for i in range(200):\n",
    "        net[out].add_connection(random.choice(net.priorities[:-net.n_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-04 *\n",
      "       1.0013)\n",
      "tensor(1.00000e-02 *\n",
      "       2.3556)\n",
      "tensor(1.00000e-05 *\n",
      "       8.2613)\n",
      "tensor(2.2934)\n",
      "tensor(1.00000e-03 *\n",
      "       6.8134)\n",
      "tensor(2.2391)\n",
      "tensor(0.5518)\n",
      "tensor(2.1297)\n",
      "tensor(0.7814)\n",
      "tensor(2.1010)\n",
      "tensor(0.5462)\n",
      "tensor(2.0809)\n",
      "tensor(1.00000e-02 *\n",
      "       9.9935)\n",
      "tensor(2.0463)\n",
      "tensor(1.00000e-02 *\n",
      "       1.4612)\n",
      "tensor(2.0669)\n",
      "tensor(1.00000e-03 *\n",
      "       7.7257)\n",
      "tensor(2.0576)\n",
      "tensor(0.8414)\n",
      "tensor(2.0641)\n",
      "tensor(0.4435)\n",
      "tensor(2.0619)\n",
      "tensor(0.1555)\n",
      "tensor(2.0561)\n",
      "tensor(1.00000e-02 *\n",
      "       2.8795)\n",
      "tensor(2.0458)\n",
      "tensor(0.5647)\n",
      "tensor(2.0603)\n",
      "tensor(1.00000e-02 *\n",
      "       1.9088)\n",
      "tensor(2.0593)\n",
      "tensor(0.5694)\n",
      "tensor(2.0859)\n",
      "tensor(1.00000e-02 *\n",
      "       1.4740)\n",
      "tensor(2.0497)\n",
      "tensor(1.00000e-02 *\n",
      "       1.6112)\n",
      "tensor(2.0988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-c4e92f314bd5>\", line 9, in <module>\n",
      "    out = net(images[j])\n",
      "  File \"<ipython-input-5-d9b034cde9d6>\", line 31, in __call__\n",
      "    self.enter(inputs)\n",
      "  File \"<ipython-input-5-d9b034cde9d6>\", line 43, in enter\n",
      "    for neuron, t in zip(self,inputs):\n",
      "  File \"<ipython-input-5-d9b034cde9d6>\", line 28, in __iter__\n",
      "    yield self.net[p]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 421, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 86, in join\n",
      "    for b in map(os.fspath, p):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4681) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "running_loss = 0\n",
    "for epoch in range(20):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        temp = []\n",
    "        for j in range(batch_size):\n",
    "            out = net(images[j])\n",
    "            out = F.softmax(out,dim=0)\n",
    "            temp.append(out)\n",
    "        out = torch.stack(temp)\n",
    "        loss = loss_fn(out,labels)\n",
    "        loss.backward()\n",
    "        running_loss += loss\n",
    "        if i % 100 == 0:\n",
    "            print(out[0,labels[0]])\n",
    "            print(running_loss/100)\n",
    "            running_loss = 0\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "it = iter(testloader)\n",
    "for i in range(200):\n",
    "    images, labels = it.next()\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images[0]))\n",
    "    out = net(images[0])\n",
    "    _, index = torch.max(out,0)\n",
    "    if(index == labels[0]):\n",
    "        correct += 1\n",
    "    print(index,labels[0])\n",
    "print(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
