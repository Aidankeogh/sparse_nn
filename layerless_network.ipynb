{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import gauss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputNeuron():\n",
    "    def __init__(self, network):\n",
    "        self.net = network # the network this belongs to\n",
    "        self.a = torch.tensor(0., requires_grad = False)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.priority) + \"\\t\" + str(float(self.a))\n",
    "        \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, network, a_func = F.relu):\n",
    "        self.net = network # the network this belongs to\n",
    "        \n",
    "        self.f = a_func\n",
    "        self.a = torch.tensor(0., requires_grad = True) # The activation value of the neuron\n",
    "        self.w = torch.tensor([gauss(0,0.1)],requires_grad = True ) # The weights \n",
    "        self.i = torch.tensor([0.], requires_grad = False) # The input values\n",
    "        \n",
    "        self.in_keys = [] # keys to grab inputs from\n",
    "        self.num_connections = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return   str(float(self.a)) + \"\\t\" + str(self.in_keys)\n",
    "            \n",
    "    \n",
    "    def forward(self):\n",
    "        temp = [torch.tensor(1.)] # bias\n",
    "        for key in self.in_keys:\n",
    "            temp.append(self.net[key].a)\n",
    "        self.i = torch.stack(temp)\n",
    "        self.a = torch.dot(self.i,self.w)\n",
    "        self.a = self.f(self.a)\n",
    "        \n",
    "    def add_connection(self,index):\n",
    "        self.w.requires_grad = False\n",
    "        self.w = torch.cat([self.w, torch.tensor([gauss(0,1)])])\n",
    "        self.i = torch.cat([self.i, torch.tensor([0.])])\n",
    "        self.w.requires_grad = True\n",
    "        \n",
    "        self.in_keys.append(index)\n",
    "        self.num_connections += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self,n_in,n_out,max_hidden = 5000, out_a_func = identity): \n",
    "        # self.net actually links them to their node. \n",
    "        self.max = max_hidden\n",
    "        self.net = [] # Ordered in terms of priority\n",
    "        self.cur = 0\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.outputs = torch.empty(n_out, requires_grad=True)\n",
    "        \n",
    "        for i in range(n_in):\n",
    "            p = i/n_in\n",
    "            self.net.append(InputNeuron(self))\n",
    "            \n",
    "        for i in range(n_out):\n",
    "            p = 9+i/n_out\n",
    "            self.net.append(Neuron(self))\n",
    "            \n",
    "    def __getitem__(self,key):\n",
    "        return self.net[key]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.net)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for n in self.net:\n",
    "            yield n\n",
    "            \n",
    "    def __call__(self,inputs):\n",
    "        self.enter(inputs)\n",
    "        self.forward()\n",
    "        return self.outputs\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        # For all non inputs, return weights\n",
    "        for n in self.net[self.n_in:]:\n",
    "            params.append(n.w)\n",
    "        return params\n",
    "\n",
    "    def enter(self,inputs):\n",
    "        inputs = inputs.view(-1)\n",
    "        # For all inputs, set to t\n",
    "        for n, i in zip(self.net[:self.n_in],inputs):\n",
    "            n.a = i\n",
    "            \n",
    "    def forward(self):\n",
    "        for n in self.net:\n",
    "            n.forward()\n",
    "        temp = [n.a for n in self.net[-self.n_out:]]\n",
    "        self.outputs = torch.stack(temp)\n",
    "        [n.a.retain_grad() for n in self.net]\n",
    "        \n",
    "    def add_neuron(self,in_connections,out_connections):\n",
    "        \n",
    "        new_priority = min(out_connections + [len(self.net) - self.n_out])\n",
    "        # New neurons have to before out any out connections\n",
    "        \n",
    "        #Move connections to account for new node in list\n",
    "        for n in self.net[new_priority:]:\n",
    "            for i in range(len(n.in_keys)):\n",
    "                if(n.in_keys[i] > new_priority):\n",
    "                    n.in_keys[i] += 1\n",
    "        \n",
    "        self.net.insert(new_priority, Neuron(self))\n",
    "        for i in in_connections:\n",
    "            self.net[new_priority].add_connection(i)\n",
    "        for o in out_connections:\n",
    "            self.net[o+1].add_connection(new_priority)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net = Network(800,4)\n",
    "inputs = torch.randn(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net.add_neuron([0,0.75,0.875],[9])\n",
    "net.add_neuron([0.125,0.75,0.875],[9.25])\n",
    "net.add_neuron([0,0.25,0.5],[9.5])\n",
    "net.add_neuron([0,0.75,0.375],[9.75])\n",
    "#net[9].add_connection(0.875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "target = torch.tensor([10.0,5.0,3.0,20.0])\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    inputs = torch.randn(800)\n",
    "    out = net(inputs)\n",
    "    loss = loss_fn(out,target)\n",
    "    loss.backward()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(out)\n",
    "        print(net[9].w)\n",
    "    #tqdm.write(str(net[9].a.grad))\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  8,  2,  2,  1,  7,  5,  7,  1,  3,  1,  2,  9,  4,\n",
      "         3,  5,  1,  0,  0,  3,  3,  9,  2,  1,  5,  9,  2,  9,\n",
      "         6,  8,  5,  1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(28*28,10)\n",
    "#Add random connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for n in net[net.n_in:]:\n",
    "    print(n.in_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3291)\n",
      "tensor(2.3029)\n",
      "tensor(2.2918)\n",
      "tensor(2.2861)\n",
      "tensor(2.2454)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-235856ea502b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/usr/local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i in range(5):\n",
    "        out = random.choice(range(len(net)-net.n_out,len(net)))\n",
    "        in_conns = []\n",
    "        for j in range(20):\n",
    "            in_conns.append(random.choice(range(0,len(net)-net.n_out)))\n",
    "            net.add_neuron(in_conns,[out])\n",
    "            \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        if i > 50:\n",
    "            break\n",
    "        images, labels = data\n",
    "        temp = []\n",
    "        for j in range(batch_size):\n",
    "            out = net(images[j])\n",
    "            out = F.softmax(out,dim=0)\n",
    "            temp.append(out)\n",
    "        out = torch.stack(temp)\n",
    "        loss = loss_fn(out,labels)\n",
    "        loss.backward()\n",
    "        running_loss += loss\n",
    "        if i % 10 == 9:\n",
    "            print(running_loss/10)\n",
    "            running_loss = 0\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "it = iter(testloader)\n",
    "for i in range(200):\n",
    "    images, labels = it.next()\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images[0]))\n",
    "    out = net(images[0])\n",
    "    _, index = torch.max(out,0)\n",
    "    if(index == labels[0]):\n",
    "        correct += 1\n",
    "    print(index,labels[0])\n",
    "print(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
