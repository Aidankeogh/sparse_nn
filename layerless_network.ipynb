{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import gauss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputNeuron():\n",
    "    def __init__(self, network, priority):\n",
    "        self.priority = priority\n",
    "        self.net = network # the network this belongs to\n",
    "        self.a = torch.tensor(0., requires_grad = False)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.priority) + \"\\t\" + str(float(self.a))\n",
    "        \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, network, priority, a_func = F.relu):\n",
    "        self.priority = priority\n",
    "        self.net = network # the network this belongs to\n",
    "        \n",
    "        self.f = a_func\n",
    "        self.a = torch.tensor(0., requires_grad = True) # The activation value of the neuron\n",
    "        self.w = torch.tensor([gauss(0,1)],requires_grad = True ) # The weights \n",
    "        self.i = torch.tensor([0.], requires_grad = False) # The input values\n",
    "        \n",
    "        self.in_keys = [] # keys to grab inputs from\n",
    "        self.num_connections = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.priority) + \"\\t\" + str(float(self.a))\n",
    "            \n",
    "    \n",
    "    def forward(self):\n",
    "        temp = [torch.tensor(1.)] # bias\n",
    "        for key in self.in_keys:\n",
    "            temp.append(self.net[key].a)\n",
    "        self.i = torch.stack(temp)\n",
    "        self.a = torch.dot(self.i,self.w)\n",
    "        self.a = self.f(self.a)\n",
    "        \n",
    "    def add_connection(self,index):\n",
    "        self.w.requires_grad = False\n",
    "        self.w = torch.cat([self.w, torch.tensor([gauss(0,1)])])\n",
    "        self.i = torch.cat([self.i, torch.tensor([0.])])\n",
    "        self.w.requires_grad = True\n",
    "        \n",
    "        self.in_keys.append(index)\n",
    "        self.num_connections += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self,n_in,n_out,max_hidden = 5000, out_a_func = identity): \n",
    "        # self.net actually links them to their node. \n",
    "        self.max = max_hidden\n",
    "        self.net = {}\n",
    "        #Priority 0-1 = input, 1-9 = hidden, 9-10 = output\n",
    "        self.priorities = []\n",
    "        self.cur = 0\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.outputs = torch.empty(n_out, requires_grad=True)\n",
    "        \n",
    "        for i in range(n_in):\n",
    "            p = i/n_in\n",
    "            self.priorities.append(p)\n",
    "            self.net[p] = InputNeuron(self, p)\n",
    "            \n",
    "        for i in range(n_out):\n",
    "            p = 9+i/n_out\n",
    "            self.priorities.append(p)\n",
    "            self.net[p] = Neuron(self, p, a_func = out_a_func)\n",
    "            \n",
    "    def __getitem__(self,key):\n",
    "        return self.net[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for p in self.priorities:\n",
    "            yield self.net[p]\n",
    "            \n",
    "    def __call__(self,inputs):\n",
    "        self.enter(inputs)\n",
    "        self.forward()\n",
    "        return self.outputs\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for p in self.priorities[self.n_in:]:\n",
    "            params.append(self[p].w)\n",
    "        return params\n",
    "\n",
    "    def enter(self,inputs):\n",
    "        inputs = inputs.view(-1)\n",
    "        for neuron, t in zip(self,inputs):\n",
    "            neuron.a = t\n",
    "            \n",
    "    def forward(self):\n",
    "        for p in self.priorities:\n",
    "            self[p].forward()\n",
    "        \n",
    "        temp = []\n",
    "        for p in self.priorities[-self.n_out:]:\n",
    "            temp.append(self[p].a)\n",
    "        self.outputs = torch.stack(temp)\n",
    "        [n.a.retain_grad() for n in net]\n",
    "        \n",
    "    def add_neuron(self,in_connections,out_connections):\n",
    "        \n",
    "        min_priority = max(in_connections + [1])\n",
    "        for p in self.priorities:\n",
    "            if p > min_priority:\n",
    "                max_priority = p\n",
    "                break\n",
    "        new_priority = (min_priority + max_priority)/2\n",
    "        self.priorities.append(new_priority)\n",
    "        self.priorities.sort()\n",
    "        self.net[new_priority] = Neuron(self,new_priority)\n",
    "        for i in in_connections:\n",
    "            self.net[new_priority].add_connection(i)\n",
    "        for o in out_connections:\n",
    "            self.net[o].add_connection(new_priority)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net = Network(800,4)\n",
    "inputs = torch.randn(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net.add_neuron([0,0.75,0.875],[9])\n",
    "net.add_neuron([0.125,0.75,0.875],[9.25])\n",
    "net.add_neuron([0,0.25,0.5],[9.5])\n",
    "net.add_neuron([0,0.75,0.375],[9.75])\n",
    "#net[9].add_connection(0.875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "target = torch.tensor([10.0,5.0,3.0,20.0])\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    inputs = torch.randn(800)\n",
    "    out = net(inputs)\n",
    "    loss = loss_fn(out,target)\n",
    "    loss.backward()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(out)\n",
    "        print(net[9].w)\n",
    "    #tqdm.write(str(net[9].a.grad))\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9,  1,  9,  1,  7,  8,  0,  5,  2,  6,  9,  3,  1,  1,\n",
      "         4,  4,  7,  0,  5,  9,  3,  7,  4,  6,  2,  2,  7,  7,\n",
      "         3,  1,  3,  7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(28*28,10)\n",
    "\n",
    "#Add random connections\n",
    "for out in net.priorities[-net.n_out:]:\n",
    "    for i in range(200):\n",
    "        net[out].add_connection(random.choice(net.priorities[:-net.n_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-04 *\n",
      "       1.0013)\n",
      "tensor(1.00000e-02 *\n",
      "       2.3556)\n",
      "tensor(1.00000e-05 *\n",
      "       8.2613)\n",
      "tensor(2.2934)\n",
      "tensor(1.00000e-03 *\n",
      "       6.8134)\n",
      "tensor(2.2391)\n",
      "tensor(0.5518)\n",
      "tensor(2.1297)\n",
      "tensor(0.7814)\n",
      "tensor(2.1010)\n",
      "tensor(0.5462)\n",
      "tensor(2.0809)\n",
      "tensor(1.00000e-02 *\n",
      "       9.9935)\n",
      "tensor(2.0463)\n",
      "tensor(1.00000e-02 *\n",
      "       1.4612)\n",
      "tensor(2.0669)\n",
      "tensor(1.00000e-03 *\n",
      "       7.7257)\n",
      "tensor(2.0576)\n",
      "tensor(0.8414)\n",
      "tensor(2.0641)\n",
      "tensor(0.4435)\n",
      "tensor(2.0619)\n",
      "tensor(0.1555)\n",
      "tensor(2.0561)\n",
      "tensor(1.00000e-02 *\n",
      "       2.8795)\n",
      "tensor(2.0458)\n",
      "tensor(0.5647)\n",
      "tensor(2.0603)\n",
      "tensor(1.00000e-02 *\n",
      "       1.9088)\n",
      "tensor(2.0593)\n",
      "tensor(0.5694)\n",
      "tensor(2.0859)\n",
      "tensor(1.00000e-02 *\n",
      "       1.4740)\n",
      "tensor(2.0497)\n",
      "tensor(1.00000e-02 *\n",
      "       1.6112)\n",
      "tensor(2.0988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-c4e92f314bd5>\", line 9, in <module>\n",
      "    out = net(images[j])\n",
      "  File \"<ipython-input-5-d9b034cde9d6>\", line 31, in __call__\n",
      "    self.enter(inputs)\n",
      "  File \"<ipython-input-5-d9b034cde9d6>\", line 43, in enter\n",
      "    for neuron, t in zip(self,inputs):\n",
      "  File \"<ipython-input-5-d9b034cde9d6>\", line 28, in __iter__\n",
      "    yield self.net[p]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 421, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/Users/keogh1/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 86, in join\n",
      "    for b in map(os.fspath, p):\n",
      "  File \"/Users/keogh1/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4681) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "running_loss = 0\n",
    "for epoch in range(20):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        temp = []\n",
    "        for j in range(batch_size):\n",
    "            out = net(images[j])\n",
    "            out = F.softmax(out,dim=0)\n",
    "            temp.append(out)\n",
    "        out = torch.stack(temp)\n",
    "        loss = loss_fn(out,labels)\n",
    "        loss.backward()\n",
    "        running_loss += loss\n",
    "        if i % 100 == 0:\n",
    "            print(out[0,labels[0]])\n",
    "            print(running_loss/100)\n",
    "            running_loss = 0\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) tensor(7)\n",
      "tensor(3) tensor(3)\n",
      "tensor(4) tensor(7)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(8)\n",
      "tensor(4) tensor(4)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(9)\n",
      "tensor(3) tensor(5)\n",
      "tensor(6) tensor(6)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(9)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(2)\n",
      "tensor(4) tensor(4)\n",
      "tensor(3) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(4)\n",
      "tensor(1) tensor(1)\n",
      "tensor(3) tensor(8)\n",
      "tensor(1) tensor(7)\n",
      "tensor(0) tensor(8)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(9)\n",
      "tensor(1) tensor(7)\n",
      "tensor(4) tensor(9)\n",
      "tensor(4) tensor(4)\n",
      "tensor(1) tensor(2)\n",
      "tensor(7) tensor(9)\n",
      "tensor(1) tensor(8)\n",
      "tensor(7) tensor(9)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(7)\n",
      "tensor(6) tensor(8)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(8)\n",
      "tensor(1) tensor(6)\n",
      "tensor(4) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(4)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(6) tensor(6)\n",
      "tensor(3) tensor(8)\n",
      "tensor(3) tensor(3)\n",
      "tensor(6) tensor(6)\n",
      "tensor(3) tensor(8)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(1)\n",
      "tensor(7) tensor(7)\n",
      "tensor(1) tensor(2)\n",
      "tensor(4) tensor(3)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(4)\n",
      "tensor(1) tensor(9)\n",
      "tensor(0) tensor(2)\n",
      "tensor(4) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(4) tensor(6)\n",
      "tensor(4) tensor(2)\n",
      "tensor(3) tensor(8)\n",
      "tensor(7) tensor(7)\n",
      "tensor(0) tensor(8)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(5)\n",
      "tensor(1) tensor(2)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(2)\n",
      "tensor(4) tensor(9)\n",
      "tensor(6) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(9)\n",
      "tensor(6) tensor(2)\n",
      "tensor(7) tensor(2)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(1)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(0)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(9)\n",
      "tensor(7) tensor(7)\n",
      "tensor(1) tensor(8)\n",
      "tensor(3) tensor(3)\n",
      "tensor(1) tensor(7)\n",
      "tensor(4) tensor(9)\n",
      "tensor(4) tensor(9)\n",
      "tensor(4) tensor(4)\n",
      "tensor(1) tensor(1)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(7)\n",
      "tensor(4) tensor(9)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(3)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(6)\n",
      "tensor(1) tensor(5)\n",
      "tensor(0) tensor(0)\n",
      "tensor(7) tensor(7)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(6) tensor(6)\n",
      "tensor(6) tensor(6)\n",
      "tensor(1) tensor(5)\n",
      "tensor(1) tensor(7)\n",
      "tensor(4) tensor(9)\n",
      "tensor(7) tensor(9)\n",
      "tensor(1) tensor(2)\n",
      "tensor(7) tensor(7)\n",
      "tensor(4) tensor(5)\n",
      "tensor(4) tensor(9)\n",
      "tensor(1) tensor(1)\n",
      "tensor(7) tensor(7)\n",
      "tensor(4) tensor(8)\n",
      "tensor(3) tensor(3)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(9)\n",
      "tensor(1) tensor(3)\n",
      "tensor(3) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(6) tensor(6)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(9)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(8)\n",
      "tensor(3) tensor(8)\n",
      "tensor(4) tensor(0)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(7)\n",
      "tensor(4) tensor(4)\n",
      "tensor(7) tensor(7)\n",
      "tensor(6) tensor(6)\n",
      "tensor(1) tensor(1)\n",
      "tensor(4) tensor(4)\n",
      "tensor(1) tensor(3)\n",
      "tensor(4) tensor(8)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(5)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(2)\n",
      "tensor(4) tensor(5)\n",
      "tensor(4) tensor(8)\n",
      "tensor(1) tensor(2)\n",
      "tensor(1) tensor(3)\n",
      "tensor(0) tensor(0)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(9)\n",
      "tensor(4) tensor(8)\n",
      "tensor(3) tensor(3)\n",
      "tensor(4) tensor(4)\n",
      "tensor(3) tensor(3)\n",
      "tensor(0) tensor(3)\n",
      "tensor(1) tensor(2)\n",
      "tensor(6) tensor(6)\n",
      "tensor(4) tensor(7)\n",
      "tensor(4) tensor(5)\n",
      "tensor(1) tensor(4)\n",
      "tensor(4) tensor(4)\n",
      "tensor(7) tensor(7)\n",
      "tensor(1) tensor(3)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(3)\n",
      "tensor(7) tensor(9)\n",
      "tensor(6) tensor(4)\n",
      "tensor(6) tensor(6)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(1)\n",
      "tensor(0) tensor(0)\n",
      "tensor(1) tensor(7)\n",
      "tensor(6) tensor(8)\n",
      "tensor(0) tensor(9)\n",
      "tensor(4) tensor(4)\n",
      "tensor(4) tensor(4)\n",
      "tensor(7) tensor(7)\n",
      "tensor(7) tensor(2)\n",
      "tensor(3) tensor(3)\n",
      "tensor(1) tensor(8)\n",
      "tensor(4) tensor(8)\n",
      "tensor(1) tensor(5)\n",
      "98\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "it = iter(testloader)\n",
    "for i in range(200):\n",
    "    images, labels = it.next()\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images[0]))\n",
    "    out = net(images[0])\n",
    "    _, index = torch.max(out,0)\n",
    "    if(index == labels[0]):\n",
    "        correct += 1\n",
    "    print(index,labels[0])\n",
    "print(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
